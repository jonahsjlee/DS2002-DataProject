{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Run below cell ONCE if copied repo to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'dsproject1.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Run below cell ONCE if in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "notebook_url = 'https://raw.githubusercontent.com/jonahsjlee/DS2002-DataProject/main/dsproject1.ipynb'\n",
    "response = requests.get(notebook_url)\n",
    "with open('dsproject1.ipynb', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "%run dsproject1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use ETL pipline application:\n",
    "    1. Run the above code cell ONCE.\n",
    "    2. Run the cell below to call the main method. This should start the ETL application and prompt the user for input.\n",
    "    3. Read the cell output carefully for application functions and options.\n",
    "    4. Type input when promted.\n",
    "\n",
    "### Notes:\n",
    "- Most errors will be raised. Read error message for reason. Other errors such as improper input will likely not have an error raised if the input is not valid. \n",
    "- Pay attention to warnings.\n",
    "- The application will continuously prompt you for actions until exit program (6) is executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataframe...\n",
      "There is currently no dataframe\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (CSV, JSON, SQL DB via upload or API call)\n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            6: Exit program\n",
      "        \n",
      "Waiting for input...\n",
      "You selected:  1\n",
      "Would you like to get your data locally or via API \n",
      " 1: Locally \n",
      " 2: API\n",
      "Waiting for input...\n",
      "You selected: Locally. Please put the file into the input_data folder and provide the file name, incuding its extension (e.g. data.csv, data.json, etc)\n",
      "Waiting for input...\n",
      "SUCESSFULLY UPLOADED DATAFRAME. Printing head...\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "   Rk         Player Class Pos          School   G   MP  TRB  AST  STL  ...  \\\n",
      "0   1   Amaree Abram    SO   G    Georgia Tech  10  108   17   11    1  ...   \n",
      "1   2   Sola Adebisi    FR   F   Florida State   7    9    1    1    0  ...   \n",
      "2   3  Prince Aligbe    SO   F  Boston College  35  651  119   21   15  ...   \n",
      "3   4     Abe Atiyeh    SR   G  Boston College   4    6    0    0    0  ...   \n",
      "4   5    Zack Austin    JR   F      Pittsburgh  33  746  137   29   32  ...   \n",
      "\n",
      "   TOV  PF  PTS    FG%    2P%    3P%    FT%   PER   WS  BPM  \n",
      "0    9  10   34  0.262  0.318  0.200  0.615   4.1 -0.1 -6.4  \n",
      "1    1   1    2  0.500  0.500    NaN    NaN   3.5  0.0 -6.7  \n",
      "2   30  51  164  0.435  0.522  0.147  0.620   9.4  0.9 -1.3  \n",
      "3    1   0    3  0.333  0.000  1.000    NaN   1.1  0.0 -8.2  \n",
      "4   13  35  216  0.417  0.563  0.295  0.737  18.0  2.9  7.9  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...\n",
      "You selected:  5\n",
      "Generating summary of dataframe...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 217 entries, 0 to 216\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Rk      217 non-null    int64  \n",
      " 1   Player  217 non-null    object \n",
      " 2   Class   217 non-null    object \n",
      " 3   Pos     217 non-null    object \n",
      " 4   School  217 non-null    object \n",
      " 5   G       217 non-null    int64  \n",
      " 6   MP      217 non-null    int64  \n",
      " 7   TRB     217 non-null    int64  \n",
      " 8   AST     217 non-null    int64  \n",
      " 9   STL     217 non-null    int64  \n",
      " 10  BLK     217 non-null    int64  \n",
      " 11  TOV     217 non-null    int64  \n",
      " 12  PF      217 non-null    int64  \n",
      " 13  PTS     217 non-null    int64  \n",
      " 14  FG%     204 non-null    float64\n",
      " 15  2P%     194 non-null    float64\n",
      " 16  3P%     182 non-null    float64\n",
      " 17  FT%     176 non-null    float64\n",
      " 18  PER     216 non-null    float64\n",
      " 19  WS      217 non-null    float64\n",
      " 20  BPM     217 non-null    float64\n",
      "dtypes: float64(7), int64(10), object(4)\n",
      "memory usage: 35.7+ KB\n",
      "None\n",
      "               Rk           G           MP         TRB         AST  \\\n",
      "count  217.000000  217.000000   217.000000  217.000000  217.000000   \n",
      "mean   109.000000   23.248848   478.331797   77.714286   32.198157   \n",
      "std     62.786676   12.467841   418.412001   78.834105   40.612468   \n",
      "min      1.000000    1.000000     0.000000    0.000000    0.000000   \n",
      "25%     55.000000   10.000000    49.000000    6.000000    1.000000   \n",
      "50%    109.000000   29.000000   371.000000   60.000000   17.000000   \n",
      "75%    163.000000   33.000000   877.000000  124.000000   46.000000   \n",
      "max    217.000000   41.000000  1333.000000  380.000000  212.000000   \n",
      "\n",
      "              STL         BLK         TOV          PF         PTS         FG%  \\\n",
      "count  217.000000  217.000000  217.000000  217.000000  217.000000  204.000000   \n",
      "mean    15.133641    8.751152   24.414747   37.695853  177.009217    0.403882   \n",
      "std     16.167973   12.631267   25.508411   32.179756  188.800355    0.153681   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000    0.000000    2.000000    7.000000   11.000000    0.356250   \n",
      "50%     11.000000    4.000000   14.000000   34.000000   98.000000    0.421000   \n",
      "75%     23.000000   10.000000   41.000000   64.000000  305.000000    0.486000   \n",
      "max     71.000000   77.000000  123.000000  113.000000  784.000000    0.701000   \n",
      "\n",
      "              2P%         3P%         FT%         PER          WS         BPM  \n",
      "count  194.000000  182.000000  176.000000  216.000000  217.000000  217.000000  \n",
      "mean     0.469304    0.287835    0.670739   10.598148    1.399078   -0.687558  \n",
      "std      0.192963    0.167308    0.190639   13.427189    1.599652   10.457621  \n",
      "min      0.000000    0.000000    0.000000 -105.800000   -0.200000  -81.800000  \n",
      "25%      0.429000    0.200000    0.580000    7.425000    0.000000   -2.200000  \n",
      "50%      0.500000    0.316500    0.691000   12.800000    0.700000    1.800000  \n",
      "75%      0.568750    0.382250    0.796250   17.400000    2.200000    4.200000  \n",
      "max      1.000000    1.000000    1.000000   37.700000    6.700000   20.900000  \n",
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...\n",
      "You selected:  6\n",
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback on errors, file not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...\n",
      "You selected:  2\n",
      "What file type would you like to convert FROM? Options include: CSV, JSON\n",
      "Waiting for input...\n",
      "What file type would you like to convert TO? Options include: CSV, JSON, SQL\n",
      "Waiting for input...\n",
      "You are converting a file from: CSV to JSON. Please put the input file into the input_data folder and provide the file name, incuding its extension (e.g. sample_data.csv, random_data.json, etc)\n",
      "Waiting for input...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File not found at the specified path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/folders/fc/srrnd06x2jj1bwj594ykym8m0000gn/T/ipykernel_55861/697483594.py:3\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res:\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/fc/srrnd06x2jj1bwj594ykym8m0000gn/T/ipykernel_55861/2364464064.py:8\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExiting program...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43moption\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/fc/srrnd06x2jj1bwj594ykym8m0000gn/T/ipykernel_55861/2364464064.py:77\u001b[0m, in \u001b[0;36mdo\u001b[0;34m(option)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------------------------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m option \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 77\u001b[0m     \u001b[43moption_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m option \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     80\u001b[0m     df \u001b[38;5;241m=\u001b[39m option_3()\n",
      "File \u001b[0;32m/var/folders/fc/srrnd06x2jj1bwj594ykym8m0000gn/T/ipykernel_55861/2364464064.py:160\u001b[0m, in \u001b[0;36moption_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter file name: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 160\u001b[0m local_df \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be converted to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_to\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_to\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCSV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJSON\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m/var/folders/fc/srrnd06x2jj1bwj594ykym8m0000gn/T/ipykernel_55861/3746455833.py:23\u001b[0m, in \u001b[0;36mfetch_data\u001b[0;34m(source, is_local)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported file format. Only CSV and JSON are supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found at the specified path.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Download from a URL\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(source)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File not found at the specified path."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2002env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
