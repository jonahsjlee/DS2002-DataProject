{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'dsproject1.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Runs:\n",
    "- To showcase functionality of program\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload csv file to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataframe...\n",
      "There is currently no dataframe\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (CSV, JSON, SQL DB via upload or API call)\n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            6: Exit program\n",
      "        \n",
      "Waiting for input...Your input: 1\n",
      "You selected:  1\n",
      "Would you like to get your data locally or via API \n",
      " 1: Locally \n",
      " 2: API\n",
      "Waiting for input...Your input: 1\n",
      "You selected: Locally. Please put the file into the input_data folder and provide the file name, incuding its extension (e.g. data.csv, data.json, etc)\n",
      "Waiting for input...Your input: sample_data.csv\n",
      "SUCESSFULLY UPLOADED DATAFRAME. Printing head...\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "   Rk         Player Class Pos          School   G   MP  TRB  AST  STL  ...  \\\n",
      "0   1   Amaree Abram    SO   G    Georgia Tech  10  108   17   11    1  ...   \n",
      "1   2   Sola Adebisi    FR   F   Florida State   7    9    1    1    0  ...   \n",
      "2   3  Prince Aligbe    SO   F  Boston College  35  651  119   21   15  ...   \n",
      "3   4     Abe Atiyeh    SR   G  Boston College   4    6    0    0    0  ...   \n",
      "4   5    Zack Austin    JR   F      Pittsburgh  33  746  137   29   32  ...   \n",
      "\n",
      "   TOV  PF  PTS    FG%    2P%    3P%    FT%   PER   WS  BPM  \n",
      "0    9  10   34  0.262  0.318  0.200  0.615   4.1 -0.1 -6.4  \n",
      "1    1   1    2  0.500  0.500    NaN    NaN   3.5  0.0 -6.7  \n",
      "2   30  51  164  0.435  0.522  0.147  0.620   9.4  0.9 -1.3  \n",
      "3    1   0    3  0.333  0.000  1.000    NaN   1.1  0.0 -8.2  \n",
      "4   13  35  216  0.417  0.563  0.295  0.737  18.0  2.9  7.9  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 6\n",
      "You selected:  6\n",
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 5\n",
      "You selected:  5\n",
      "Generating summary of dataframe...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 217 entries, 0 to 216\n",
      "Data columns (total 20 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Rk      217 non-null    int64  \n",
      " 1   Player  217 non-null    object \n",
      " 2   Class   217 non-null    object \n",
      " 3   Pos     217 non-null    object \n",
      " 4   School  217 non-null    object \n",
      " 5   G       217 non-null    int64  \n",
      " 6   MP      217 non-null    int64  \n",
      " 7   TRB     217 non-null    int64  \n",
      " 8   AST     217 non-null    int64  \n",
      " 9   STL     217 non-null    int64  \n",
      " 10  BLK     217 non-null    int64  \n",
      " 11  TOV     217 non-null    int64  \n",
      " 12  PF      217 non-null    int64  \n",
      " 13  PTS     217 non-null    int64  \n",
      " 14  FG%     204 non-null    float64\n",
      " 15  2P%     194 non-null    float64\n",
      " 16  3P%     182 non-null    float64\n",
      " 17  FT%     176 non-null    float64\n",
      " 18  PER     216 non-null    float64\n",
      " 19  WS      217 non-null    float64\n",
      "dtypes: float64(6), int64(10), object(4)\n",
      "memory usage: 34.0+ KB\n",
      "None\n",
      "               Rk           G           MP         TRB         AST  \\\n",
      "count  217.000000  217.000000   217.000000  217.000000  217.000000   \n",
      "mean   109.000000   23.248848   478.331797   77.714286   32.198157   \n",
      "std     62.786676   12.467841   418.412001   78.834105   40.612468   \n",
      "min      1.000000    1.000000     0.000000    0.000000    0.000000   \n",
      "25%     55.000000   10.000000    49.000000    6.000000    1.000000   \n",
      "50%    109.000000   29.000000   371.000000   60.000000   17.000000   \n",
      "75%    163.000000   33.000000   877.000000  124.000000   46.000000   \n",
      "max    217.000000   41.000000  1333.000000  380.000000  212.000000   \n",
      "\n",
      "              STL         BLK         TOV          PF         PTS         FG%  \\\n",
      "count  217.000000  217.000000  217.000000  217.000000  217.000000  204.000000   \n",
      "mean    15.133641    8.751152   24.414747   37.695853  177.009217    0.403882   \n",
      "std     16.167973   12.631267   25.508411   32.179756  188.800355    0.153681   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000    0.000000    2.000000    7.000000   11.000000    0.356250   \n",
      "50%     11.000000    4.000000   14.000000   34.000000   98.000000    0.421000   \n",
      "75%     23.000000   10.000000   41.000000   64.000000  305.000000    0.486000   \n",
      "max     71.000000   77.000000  123.000000  113.000000  784.000000    0.701000   \n",
      "\n",
      "              2P%         3P%         FT%         PER          WS  \n",
      "count  194.000000  182.000000  176.000000  216.000000  217.000000  \n",
      "mean     0.469304    0.287835    0.670739   10.598148    1.399078  \n",
      "std      0.192963    0.167308    0.190639   13.427189    1.599652  \n",
      "min      0.000000    0.000000    0.000000 -105.800000   -0.200000  \n",
      "25%      0.429000    0.200000    0.580000    7.425000    0.000000  \n",
      "50%      0.500000    0.316500    0.691000   12.800000    0.700000  \n",
      "75%      0.568750    0.382250    0.796250   17.400000    2.200000  \n",
      "max      1.000000    1.000000    1.000000   37.700000    6.700000  \n",
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 6\n",
      "You selected:  6\n",
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify dataframe: Remove column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 3\n",
      "You selected:  3\n",
      "How would you like to modify the dataframe? \n",
      " 1: Add column \n",
      " 2: Remove column\n",
      "Waiting for input...Your input: 2\n",
      "You selected: Remove column. Please provide the name of the column you'd like to remove\n",
      "Waiting for input...Your input: BPM\n",
      "Column 'BPM' removed.\n",
      "SUCESSFULLY MODIFIED DATAFRAME. Printing head...\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "   Rk         Player Class Pos          School   G   MP  TRB  AST  STL  BLK  \\\n",
      "0   1   Amaree Abram    SO   G    Georgia Tech  10  108   17   11    1    2   \n",
      "1   2   Sola Adebisi    FR   F   Florida State   7    9    1    1    0    0   \n",
      "2   3  Prince Aligbe    SO   F  Boston College  35  651  119   21   15    4   \n",
      "3   4     Abe Atiyeh    SR   G  Boston College   4    6    0    0    0    0   \n",
      "4   5    Zack Austin    JR   F      Pittsburgh  33  746  137   29   32   44   \n",
      "\n",
      "   TOV  PF  PTS    FG%    2P%    3P%    FT%   PER   WS  \n",
      "0    9  10   34  0.262  0.318  0.200  0.615   4.1 -0.1  \n",
      "1    1   1    2  0.500  0.500    NaN    NaN   3.5  0.0  \n",
      "2   30  51  164  0.435  0.522  0.147  0.620   9.4  0.9  \n",
      "3    1   0    3  0.333  0.000  1.000    NaN   1.1  0.0  \n",
      "4   13  35  216  0.417  0.563  0.295  0.737  18.0  2.9  \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 6\n",
      "You selected:  6\n",
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Dataframe: Add column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 3\n",
      "You selected:  3\n",
      "How would you like to modify the dataframe? \n",
      " 1: Add column \n",
      " 2: Remove column\n",
      "Waiting for input...Your input: 1\n",
      "You selected: Add column. Please provide the name of the column you'd like to add\n",
      "Waiting for input...Your input: FN\n",
      "Please provide the data you'd like to add, separated by commas\n",
      "Waiting for input...Your input: ['14', '78', '38', '51', '27', '81', '90', '94', '2', '36', '13', '90', '26', '30', '34', '53', '19', '19', '73', '84', '66', '11', '41', '55', '41', '42', '66', '75', '67', '4', '10', '38', '85', '8', '93', '36', '63', '46', '68', '46', '56', '31', '71', '43', '22', '56', '53', '90', '65', '54', '13', '83', '14', '13', '62', '66', '30', '3', '81', '51', '41', '61', '27', '92', '8', '99', '73', '77', '24', '44', '19', '96', '14', '100', '40', '51', '92', '76', '26', '97', '79', '94', '84', '19', '46', '62', '70', '87', '37', '20', '3', '44', '14', '81', '35', '40', '58', '72', '38', '70', '42', '64', '61', '94', '75', '93', '100', '80', '13', '23', '34', '33', '15', '7', '65', '46', '45', '68', '78', '15', '96', '60', '71', '82', '85', '19', '76', '59', '69', '26', '97', '88', '92', '86', '23', '30', '90', '57', '2', '48', '90', '32', '55', '98', '37', '62', '63', '79', '58', '5', '2', '92', '38', '43', '88', '85', '96', '34', '76', '32', '58', '51', '27', '90', '17', '72', '10', '13', '40', '8', '98', '21', '68', '7', '37', '85', '7', '98', '47', '29', '98', '18', '51', '84', '29', '57', '7', '10', '57', '88', '85', '66', '41', '48', '36', '85', '24', '27', '90', '67', '38', '14', '35', '24', '32', '83', '10', '63', '38', '8', '42', '7', '33', '34', '75', '53', '43']\n",
      "Column 'FN' added.\n",
      "SUCESSFULLY MODIFIED DATAFRAME. Printing head...\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "   Rk         Player Class Pos          School   G   MP  TRB  AST  STL  ...  \\\n",
      "0   1   Amaree Abram    SO   G    Georgia Tech  10  108   17   11    1  ...   \n",
      "1   2   Sola Adebisi    FR   F   Florida State   7    9    1    1    0  ...   \n",
      "2   3  Prince Aligbe    SO   F  Boston College  35  651  119   21   15  ...   \n",
      "3   4     Abe Atiyeh    SR   G  Boston College   4    6    0    0    0  ...   \n",
      "4   5    Zack Austin    JR   F      Pittsburgh  33  746  137   29   32  ...   \n",
      "\n",
      "   TOV  PF  PTS    FG%    2P%    3P%    FT%   PER   WS  FN  \n",
      "0    9  10   34  0.262  0.318  0.200  0.615   4.1 -0.1  14  \n",
      "1    1   1    2  0.500  0.500    NaN    NaN   3.5  0.0  78  \n",
      "2   30  51  164  0.435  0.522  0.147  0.620   9.4  0.9  38  \n",
      "3    1   0    3  0.333  0.000  1.000    NaN   1.1  0.0  51  \n",
      "4   13  35  216  0.417  0.563  0.295  0.737  18.0  2.9  27  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 6\n",
      "You selected:  6\n",
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize again (post process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 5\n",
      "You selected:  5\n",
      "Generating summary of dataframe...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 217 entries, 0 to 216\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Rk      217 non-null    int64  \n",
      " 1   Player  217 non-null    object \n",
      " 2   Class   217 non-null    object \n",
      " 3   Pos     217 non-null    object \n",
      " 4   School  217 non-null    object \n",
      " 5   G       217 non-null    int64  \n",
      " 6   MP      217 non-null    int64  \n",
      " 7   TRB     217 non-null    int64  \n",
      " 8   AST     217 non-null    int64  \n",
      " 9   STL     217 non-null    int64  \n",
      " 10  BLK     217 non-null    int64  \n",
      " 11  TOV     217 non-null    int64  \n",
      " 12  PF      217 non-null    int64  \n",
      " 13  PTS     217 non-null    int64  \n",
      " 14  FG%     204 non-null    float64\n",
      " 15  2P%     194 non-null    float64\n",
      " 16  3P%     182 non-null    float64\n",
      " 17  FT%     176 non-null    float64\n",
      " 18  PER     216 non-null    float64\n",
      " 19  WS      217 non-null    float64\n",
      " 20  FN      217 non-null    object \n",
      "dtypes: float64(6), int64(10), object(5)\n",
      "memory usage: 35.7+ KB\n",
      "None\n",
      "               Rk           G           MP         TRB         AST  \\\n",
      "count  217.000000  217.000000   217.000000  217.000000  217.000000   \n",
      "mean   109.000000   23.248848   478.331797   77.714286   32.198157   \n",
      "std     62.786676   12.467841   418.412001   78.834105   40.612468   \n",
      "min      1.000000    1.000000     0.000000    0.000000    0.000000   \n",
      "25%     55.000000   10.000000    49.000000    6.000000    1.000000   \n",
      "50%    109.000000   29.000000   371.000000   60.000000   17.000000   \n",
      "75%    163.000000   33.000000   877.000000  124.000000   46.000000   \n",
      "max    217.000000   41.000000  1333.000000  380.000000  212.000000   \n",
      "\n",
      "              STL         BLK         TOV          PF         PTS         FG%  \\\n",
      "count  217.000000  217.000000  217.000000  217.000000  217.000000  204.000000   \n",
      "mean    15.133641    8.751152   24.414747   37.695853  177.009217    0.403882   \n",
      "std     16.167973   12.631267   25.508411   32.179756  188.800355    0.153681   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000    0.000000    2.000000    7.000000   11.000000    0.356250   \n",
      "50%     11.000000    4.000000   14.000000   34.000000   98.000000    0.421000   \n",
      "75%     23.000000   10.000000   41.000000   64.000000  305.000000    0.486000   \n",
      "max     71.000000   77.000000  123.000000  113.000000  784.000000    0.701000   \n",
      "\n",
      "              2P%         3P%         FT%         PER          WS  \n",
      "count  194.000000  182.000000  176.000000  216.000000  217.000000  \n",
      "mean     0.469304    0.287835    0.670739   10.598148    1.399078  \n",
      "std      0.192963    0.167308    0.190639   13.427189    1.599652  \n",
      "min      0.000000    0.000000    0.000000 -105.800000   -0.200000  \n",
      "25%      0.429000    0.200000    0.580000    7.425000    0.000000  \n",
      "50%      0.500000    0.316500    0.691000   12.800000    0.700000  \n",
      "75%      0.568750    0.382250    0.796250   17.400000    2.200000  \n",
      "max      1.000000    1.000000    1.000000   37.700000    6.700000  \n",
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 6\n",
      "You selected:  6\n",
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 4\n",
      "You selected:  4\n",
      "How would you like the dataframe to be stored? Options: \n",
      " 1: Write to local disk as CSV or JSON \n",
      " 2: Write to SQL database\n",
      "Waiting for input...Your input: 1\n",
      "You selected: Write to local disk. Please provide what you want the file to be named, including the extension. (e.g. 'output_file.csv', 'my_file.json', etc.) Please note only CSV and JSON is supported. The file will be written to the folder output_data\n",
      "Waiting for input...Your input: output_sample.json\n",
      "DataFrame exported as JSON to output_data/output_sample.json\n",
      "SUCESSFULLY EXPORTED DATAFRAME. Path to file: output_data/output_sample.json\n",
      "SUCESSFULLY EXPORTED DATAFRAME\n",
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 6\n",
      "You selected:  6\n",
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data via API (Kaggle) and export to CSV, convert kaggle dataset to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 1\n",
      "WARNING: If existing data has not been exported, it will be lost. Do you wish to continue (Y/N)\n",
      "Waiting for input...You selected:  1\n",
      "Would you like to get your data locally or via API \n",
      " 1: Locally \n",
      " 2: API\n",
      "Waiting for input...Your input: 2\n",
      "You selected: via API. Please provide the URL for the API to retrieve the data. Note, the URL must link diirectly to JSON data, or a CSV or JSON file or zip archive containing the CSV/JSON file\n",
      "Waiting for input...Your input: https://www.kaggle.com/api/v1/datasets/download/jvanark/nvidia-daily-stock-price-data\n",
      "SUCESSFULLY UPLOADED DATAFRAME. Printing head...\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "         Date      Open      High       Low     Close      Volume\n",
      "0  2004-01-02  0.196417  0.199083  0.192333  0.192333   436416000\n",
      "1  2004-01-05  0.195250  0.199917  0.193500  0.198583   575292000\n",
      "2  2004-01-06  0.198000  0.209417  0.197083  0.206667  1093344000\n",
      "3  2004-01-07  0.204333  0.209500  0.202917  0.208500   673032000\n",
      "4  2004-01-08  0.211083  0.212083  0.207250  0.209250   433752000\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 4\n",
      "You selected:  4\n",
      "How would you like the dataframe to be stored? Options: \n",
      " 1: Write to local disk as CSV or JSON \n",
      " 2: Write to SQL database\n",
      "Waiting for input...Your input: 1\n",
      "You selected: Write to local disk. Please provide what you want the file to be named, including the extension. (e.g. 'output_file.csv', 'my_file.json', etc.) Please note only CSV and JSON is supported. The file will be written to the folder output_data\n",
      "Waiting for input...Your input: nvida_stock.csv\n",
      "DataFrame exported as CSV to output_data/nvida_stock.csv\n",
      "SUCESSFULLY EXPORTED DATAFRAME. Path to file: output_data/nvida_stock.csv\n",
      "SUCESSFULLY EXPORTED DATAFRAME\n",
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 6\n",
      "You selected:  6\n",
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covert File Types: JSON to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 2\n",
      "You selected:  2\n",
      "What file type would you like to convert FROM? Options include: CSV, JSON\n",
      "Waiting for input...Your input: JSON\n",
      "What file type would you like to convert TO? Options include: CSV, JSON, SQL\n",
      "Waiting for input...Your input: CSV\n",
      "You are converting a file from: JSON to CSV. Please put the input file into the input_data folder and provide the file name, incuding its extension (e.g. sample_data.csv, random_data.json, etc)\n",
      "Waiting for input...Your input: random_data.json\n",
      "The file random_data.json will be converted to CSV\n",
      "Please provide what you want the file to be named, EXCLUDING the extension. (e.g. 'output_file', 'my_file', etc.) The file will be written to the folder output_data\n",
      "Waiting for input...Your input: random_data.csv\n",
      "file name: random_data.csv\n",
      "DataFrame exported as CSV to output_data/random_data.csv\n",
      "SUCESSFULLY COVERTED TO CSV. Path to file: output_data/random_data.csv\n",
      "Validating dataframe...\n",
      "Existing data detected!\n",
      "ETL Pipeline: What would you like to do?\n",
      "Available Options:\n",
      "            1: Fetch or Upload Data (Overwrite existing data) \n",
      "            2: Convert file types (CSV, JSON, SQL DB). THIS ACTION IS INDEPENDENT OF EXISTING DATAFRAME.\n",
      "            3: Modify dataframe (Add or remove column)\n",
      "            4: Export/Store Data to disk or database\n",
      "            5: Summarize current dataframe\n",
      "            6: Exit program\n",
      "            \n",
      "Waiting for input...Your input: 6\n",
      "You selected:  6\n",
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2002env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
